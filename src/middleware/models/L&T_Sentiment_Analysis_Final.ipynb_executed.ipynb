{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae33e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T12:42:28.193427Z",
     "iopub.status.busy": "2024-03-21T12:42:28.191881Z",
     "iopub.status.idle": "2024-03-21T12:43:09.975669Z",
     "shell.execute_reply": "2024-03-21T12:43:09.971427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@user', 'L&T', 'is', 'such', 'a', 'cool', 'company', 'http']\n",
      "@user L&T is such a cool company http\n",
      "Negative 0.0015705187\n",
      "Neutral 0.018332109\n",
      "Positive 0.9800973\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "tweet = \"@MehranShakarami L&T is such a cool company https://mehranshakarami.com\"\n",
    "#preprocess tweet\n",
    "tweet_words = []\n",
    "\n",
    "for word in tweet.split(' '):\n",
    "    if word.startswith('@') and len(word) > 1:\n",
    "        word = '@user'\n",
    "    elif word.startswith('http'):\n",
    "        word = \"http\"\n",
    "    tweet_words.append(word)\n",
    "\n",
    "print(tweet_words)\n",
    "\n",
    "tweet_proc = \" \".join(tweet_words)\n",
    "print(tweet_proc)\n",
    "\n",
    "#load model and tokenizer\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# sentiment analysis\n",
    "encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
    "# output = model(encoded_tweet['input_ids'],encoded_tweet['attention_mask'])\n",
    "# print(output)\n",
    "\n",
    "output = model(**encoded_tweet)\n",
    "\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    l = labels[i]\n",
    "    s = scores[i]\n",
    "    print(l,s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e0d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20830faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58c5bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T12:43:09.993806Z",
     "iopub.status.busy": "2024-03-21T12:43:09.992642Z",
     "iopub.status.idle": "2024-03-21T12:43:10.022355Z",
     "shell.execute_reply": "2024-03-21T12:43:10.016680Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1047f707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T12:43:10.046294Z",
     "iopub.status.busy": "2024-03-21T12:43:10.044547Z",
     "iopub.status.idle": "2024-03-21T12:43:10.081065Z",
     "shell.execute_reply": "2024-03-21T12:43:10.078905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "tweets_loaded = pickle.load(open('./l&t_tweets_scraped','rb'))\n",
    "print((len(tweets_loaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581aec05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T12:43:10.098839Z",
     "iopub.status.busy": "2024-03-21T12:43:10.097510Z",
     "iopub.status.idle": "2024-03-21T12:43:30.415541Z",
     "shell.execute_reply": "2024-03-21T12:43:30.413277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative 0.024210352\n",
      "Neutral 0.8286833\n",
      "Positive 0.14710645\n",
      "Negative 0.6328187\n",
      "Neutral 0.3430486\n",
      "Positive 0.02413276\n",
      "Negative 0.046127893\n",
      "Neutral 0.8687469\n",
      "Positive 0.08512522\n",
      "Negative 0.027336482\n",
      "Neutral 0.90723354\n",
      "Positive 0.06542993\n",
      "Negative 0.090137385\n",
      "Neutral 0.85841835\n",
      "Positive 0.05144419\n",
      "Negative 0.031699944\n",
      "Neutral 0.9076874\n",
      "Positive 0.060612604\n",
      "Negative 0.0067844177\n",
      "Neutral 0.5085931\n",
      "Positive 0.48462236\n",
      "Negative 0.009202385\n",
      "Neutral 0.5681063\n",
      "Positive 0.42269132\n",
      "Negative 0.03430619\n",
      "Neutral 0.8628514\n",
      "Positive 0.10284235\n",
      "Negative 0.0031782975\n",
      "Neutral 0.05874535\n",
      "Positive 0.93807644\n",
      "Negative 0.02082661\n",
      "Neutral 0.73442584\n",
      "Positive 0.24474758\n",
      "Negative 0.008387374\n",
      "Neutral 0.7517822\n",
      "Positive 0.23983051\n",
      "Negative 0.0047788904\n",
      "Neutral 0.34845662\n",
      "Positive 0.6467646\n",
      "Negative 0.07196513\n",
      "Neutral 0.89792854\n",
      "Positive 0.030106502\n",
      "Negative 0.11141272\n",
      "Neutral 0.8256233\n",
      "Positive 0.06296398\n",
      "['Neutral', 'Negative', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Positive', 'Neutral', 'Neutral', 'Positive', 'Neutral', 'Neutral'] [0.8286833, 0.6328187, 0.8687469, 0.90723354, 0.85841835, 0.9076874, 0.5085931, 0.5681063, 0.8628514, 0.93807644, 0.73442584, 0.7517822, 0.6467646, 0.89792854, 0.8256233]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "#loading model and tokenizer\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "prediction_labels_lst=[]\n",
    "prediction_scores_lst=[]\n",
    "\n",
    "for tweet in tweets_loaded:\n",
    "    \n",
    "\n",
    "    # sentiment analysis\n",
    "    encoded_tweet = tokenizer(tweet[2], return_tensors='pt')\n",
    "    # output = model(encoded_tweet['input_ids'],encoded_tweet['attention_mask'])\n",
    "    # print(output)\n",
    "\n",
    "    output = model(**encoded_tweet)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "\n",
    "    for i in range(len(scores)):\n",
    "        l = labels[i]\n",
    "        s = scores[i]\n",
    "        print(l,s)\n",
    "    if scores[0]>scores[1] and scores[0]>scores[2]:\n",
    "        prediction_labels_lst.append(labels[0])\n",
    "        prediction_scores_lst.append(scores[0])\n",
    "    elif scores[1]>scores[0] and scores[1]>scores[2]:\n",
    "        prediction_labels_lst.append(labels[1])\n",
    "        prediction_scores_lst.append(scores[1])\n",
    "    else:\n",
    "        prediction_labels_lst.append(labels[2])\n",
    "        prediction_scores_lst.append(scores[2])\n",
    "\n",
    "\n",
    "print(prediction_labels_lst,prediction_scores_lst)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6804be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T12:43:30.429072Z",
     "iopub.status.busy": "2024-03-21T12:43:30.428085Z",
     "iopub.status.idle": "2024-03-21T12:43:30.478413Z",
     "shell.execute_reply": "2024-03-21T12:43:30.475768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction_labels': ['Neutral', 'Negative', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Positive', 'Neutral', 'Neutral', 'Positive', 'Neutral', 'Neutral'], 'prediction_scores': [0.8286833, 0.6328187, 0.8687469, 0.90723354, 0.85841835, 0.9076874, 0.5085931, 0.5681063, 0.8628514, 0.93807644, 0.73442584, 0.7517822, 0.6467646, 0.89792854, 0.8256233], 'tweet_id': ['AjayshreeSamby3', 'Pradyumnapintoo', 'ExtraaGyan', 'ET_Infra', 'BiginfoI', 'TheWealthelite', 'TheWealthelite', 'MicrosoftIndia', 'getblinkx', 'JayantKrishnaIN', 'Ashutos66391798', 'FI_Broking', 'Shiba11651', 'annuclint', 'IndexKarnataka'], 'tweet': ['S-81 Issac Pearl. The Spanish offering for P-75I by @NavantiaOficial along with @larsentoubro . First ever inside access to this 3000 ton giant Submarine while in active duty.\\nhttps://t.co/HVgqPOFo6f', '@epfobandra@larsentoubro@pmo\\n\\nThis is to bring to your notice that one of my Cousin is trying his level best to update his kyc and signature on epfo portal but due to negligence at Lnt official its not being resolved. We are going through though time meanwhile they are least..', 'NCC LIMITED INFLATION ADJUSTED CHART:\\n-700+ MINIMUM \\n-40% PAT AND REVENUE GROWTH IN LAST 2 YEARS\\n-57000 CRORE + ORDER BOOK\\n-LOWEST DEBT TO EQUTY IN INFRA COMPANIES\\n-CAPEX BOOM\\n-HIGH FII STAKE\\n#ncc #ncclimited #niftyinfra #LarsenToubro #niftysmallcap #Multibaggers #chart https://t.co/bEVFpckFB7', 'Larsen &amp; Toubro buys 1.20 cr units of National Highways Infra Trust https://t.co/a5xH2bOvaP via @ET_Infra @larsentoubro #nahi #InvIt #highway #construction', '#Contract Update: Larsen &amp; Toubro bags order for Lift Irrigation project in #Odisha \\n\\nProject Cost\\xa0- 587 Crore\\n\\nCompletion Period\\xa0- 36 Months\\n\\n@OdishaWater \\n@larsentoubro \\n@BiginfoI \\n@investindia \\n\\n#LatestNews #Odisha #irrigation #thursdayvibes #Election2024 #Holi2024 #Updates https://t.co/NQcH0RJ4UN', 'Top holdings of #Quant Flexi Cap Fund  \\n\\n#RelianceIndustries \\n#JioFinance \\n#Swanenergy \\n#HUDCO \\n#AdaniPower \\n#Larsentoubro \\n#Biocon \\n#britannia \\n#Hindalco \\n#LIC \\n#SAIL', '#HDFCBank #LarsenToubro #ICICIBank #TataSteel #AxisBank are top contributors to the #Nifty50.', \"Advancing towards an AI-first approach, @larsentoubro's cognitive services leveraged #NLP &amp; #GenAI on #AzureOpenAI to extract key data from documents, identified crucial contract clauses, technical details in emails and reports, and insights from across projects #AIFirstMovers https://t.co/wwobMNQDr4\", 'Technical Short Term\\n\\nBUY – Larsen and Toubro Ltd.\\n\\n#LandT #larsentoubro #larsenandtubro #larsenturboltd #nifty #banknifty #viralpost #nse #bse #nifty50 #trading #intradaytrading #stockmarketindia #markets #stockmarket #investor #investments #finance #research #MadeForTheMarket #blinkX #getblinkX', \"Loved experiencing India's 1st undersea tunnel's 2-km stretch under Arabian Sea as 1st phase of coastal road between Worli &amp; Marine Drive, an 10.5-km-long marvel by @mybmc &amp; @larsentoubro that will save $100 m/year in carbon emissions @mybmcCoastalRd @CMOMaharashtra @narendramodi https://t.co/2Qo5YFFkwX\", '@IndexKarnataka @larsentoubro 👍', '👉L&amp;T Technology Services on Wednesday said that it was planning to train 1,000 engineers in #Nvidia’s GenAI software.\\n\\n#larsentoubro', 'Fruits\\n\\nHealth Benefits:\\n- High source of antioxidants \\n- Improves heart health\\n\\n59th Challenge on - 21st Mar 2024\\n@larsentoubro\\n@GOQii\\n@GOQiiLife\\n#GOQiiCorporateChallenge \\n\\n#fruits #fruitbasket #kiwi #kiwifruit \\n#healthyeating #fitnesstips  #fitatanyage #fitatforty #FitAtFifty https://t.co/sdhhs1vRnk', '@IndexKarnataka @larsentoubro What about Whitefield line? 🤔', '. @larsentoubro has hit the ground in #Kanaka corridor!\\n\\nMeanwhile SWR transfers 115 acres for kanaka line\\n\\n#Heelalige\\n\\nL&amp;T workers spotted at #Heelalige railway station (survey &amp; construction workers with L&amp;T helmet) https://t.co/b8sdShCyZR']}\n"
     ]
    }
   ],
   "source": [
    "tweet_ids=[]\n",
    "tweet_content=[]\n",
    "for tweet_info in tweets_loaded:\n",
    "    tweet_ids.append(tweet_info[0]) # This is the username\n",
    "for tweet_info in tweets_loaded:\n",
    "    tweet_content.append(tweet_info[2])\n",
    "    \n",
    "\n",
    "data_to_dump = {\"prediction_labels\":prediction_labels_lst, \"prediction_scores\":prediction_scores_lst, \"tweet_id\":tweet_ids}  \n",
    "print(data_to_dump)\n",
    "import json\n",
    "# Dump the data using pickle\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(str(data_to_dump), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd16b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
